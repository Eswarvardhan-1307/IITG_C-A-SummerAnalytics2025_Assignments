{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf21306-bcd7-4da8-9eb3-d7017e071de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Head:\n",
      "      SEQN  RIAGENDR  PAQ605  BMXBMI  LBXGLU  DIQ010  LBXGLT  LBXIN age_group\n",
      "0  73564.0       2.0     2.0    35.7   110.0     2.0   150.0  14.91     Adult\n",
      "1  73568.0       2.0     2.0    20.3    89.0     2.0    80.0   3.85     Adult\n",
      "2  73576.0       1.0     2.0    23.2    89.0     2.0    68.0   6.14     Adult\n",
      "3  73577.0       1.0     2.0    28.9   104.0     NaN    84.0  16.15     Adult\n",
      "4  73580.0       2.0     1.0    35.9   103.0     2.0    81.0  10.92     Adult\n",
      "\n",
      "Train Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1966 entries, 0 to 1965\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   SEQN       1954 non-null   float64\n",
      " 1   RIAGENDR   1948 non-null   float64\n",
      " 2   PAQ605     1953 non-null   float64\n",
      " 3   BMXBMI     1948 non-null   float64\n",
      " 4   LBXGLU     1953 non-null   float64\n",
      " 5   DIQ010     1948 non-null   float64\n",
      " 6   LBXGLT     1955 non-null   float64\n",
      " 7   LBXIN      1957 non-null   float64\n",
      " 8   age_group  1952 non-null   object \n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 138.4+ KB\n",
      "None\n",
      "\n",
      "Test Data Head:\n",
      "      SEQN  RIAGENDR  PAQ605  BMXBMI  LBXGLU  DIQ010  LBXGLT  LBXIN\n",
      "0  77017.0       1.0     1.0    32.2    96.0     2.0   135.0  15.11\n",
      "1  75580.0       2.0     2.0    26.3   100.0     2.0   141.0  15.26\n",
      "2  73820.0       1.0     2.0    28.6   107.0     2.0   136.0   8.82\n",
      "3  80489.0       2.0     1.0    22.1    93.0     2.0   111.0  12.13\n",
      "4  82047.0       1.0     1.0    24.7    91.0     2.0   105.0   3.12\n",
      "\n",
      "Test Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 312 entries, 0 to 311\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   SEQN      310 non-null    float64\n",
      " 1   RIAGENDR  310 non-null    float64\n",
      " 2   PAQ605    311 non-null    float64\n",
      " 3   BMXBMI    311 non-null    float64\n",
      " 4   LBXGLU    311 non-null    float64\n",
      " 5   DIQ010    311 non-null    float64\n",
      " 6   LBXGLT    310 non-null    float64\n",
      " 7   LBXIN     311 non-null    float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 19.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv('Train_Data.csv')\n",
    "test_df = pd.read_csv('Test_Data.csv')\n",
    "sample_submission_df = pd.read_csv('Sample_Submission.csv')\n",
    "\n",
    "# Display the first few rows of the training data\n",
    "print(\"Train Data Head:\")\n",
    "print(train_df.head())\n",
    "\n",
    "# Display information about the training data\n",
    "print(\"\\nTrain Data Info:\")\n",
    "print(train_df.info())\n",
    "\n",
    "# Display the first few rows of the test data\n",
    "print(\"\\nTest Data Head:\")\n",
    "print(test_df.head())\n",
    "\n",
    "# Display information about the test data\n",
    "print(\"\\nTest Data Info:\")\n",
    "print(test_df.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d7685b-3766-42a7-9e33-ff7f6f8fa3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded successfully.\n",
      "\n",
      "--- Initial Data Info ---\n",
      "Train Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1966 entries, 0 to 1965\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   SEQN       1954 non-null   float64\n",
      " 1   RIAGENDR   1948 non-null   float64\n",
      " 2   PAQ605     1953 non-null   float64\n",
      " 3   BMXBMI     1948 non-null   float64\n",
      " 4   LBXGLU     1953 non-null   float64\n",
      " 5   DIQ010     1948 non-null   float64\n",
      " 6   LBXGLT     1955 non-null   float64\n",
      " 7   LBXIN      1957 non-null   float64\n",
      " 8   age_group  1952 non-null   object \n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 138.4+ KB\n",
      "\n",
      "Test Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 312 entries, 0 to 311\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   SEQN      310 non-null    float64\n",
      " 1   RIAGENDR  310 non-null    float64\n",
      " 2   PAQ605    311 non-null    float64\n",
      " 3   BMXBMI    311 non-null    float64\n",
      " 4   LBXGLU    311 non-null    float64\n",
      " 5   DIQ010    311 non-null    float64\n",
      " 6   LBXGLT    310 non-null    float64\n",
      " 7   LBXIN     311 non-null    float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 19.6 KB\n",
      "\n",
      "--- After dropping SEQN ---\n",
      "Train Data Columns: ['RIAGENDR', 'PAQ605', 'BMXBMI', 'LBXGLU', 'DIQ010', 'LBXGLT', 'LBXIN', 'age_group']\n",
      "Test Data Columns: ['RIAGENDR', 'PAQ605', 'BMXBMI', 'LBXGLU', 'DIQ010', 'LBXGLT', 'LBXIN']\n",
      "\n",
      "Missing values in 'age_group' handled: 0 remaining.\n",
      "\n",
      "--- After Imputation ---\n",
      "Train Data NaNs after numerical and categorical imputation:\n",
      " RIAGENDR     0\n",
      "PAQ605       0\n",
      "BMXBMI       0\n",
      "LBXGLU       0\n",
      "DIQ010       0\n",
      "LBXGLT       0\n",
      "LBXIN        0\n",
      "age_group    0\n",
      "dtype: int64\n",
      "Test Data NaNs after numerical and categorical imputation:\n",
      " RIAGENDR    0\n",
      "PAQ605      0\n",
      "BMXBMI      0\n",
      "LBXGLU      0\n",
      "DIQ010      0\n",
      "LBXGLT      0\n",
      "LBXIN       0\n",
      "dtype: int64\n",
      "\n",
      "'age_group' mapped to numerical (0=Adult, 1=Senior).\n",
      "\n",
      "'DIQ010' one-hot encoded.\n",
      "\n",
      "--- After all preprocessing and final imputation ---\n",
      "Train Data Columns: ['RIAGENDR', 'PAQ605', 'BMXBMI', 'LBXGLU', 'LBXGLT', 'LBXIN', 'age_group', 'DIQ010_1.0', 'DIQ010_2.0', 'DIQ010_3.0']\n",
      "Test Data Columns: ['RIAGENDR', 'PAQ605', 'BMXBMI', 'LBXGLU', 'LBXGLT', 'LBXIN', 'DIQ010_1.0', 'DIQ010_2.0', 'DIQ010_3.0']\n",
      "Train Data NaNs:\n",
      " RIAGENDR      0\n",
      "PAQ605        0\n",
      "BMXBMI        0\n",
      "LBXGLU        0\n",
      "LBXGLT        0\n",
      "LBXIN         0\n",
      "age_group     0\n",
      "DIQ010_1.0    0\n",
      "DIQ010_2.0    0\n",
      "DIQ010_3.0    0\n",
      "dtype: int64\n",
      "Test Data NaNs:\n",
      " RIAGENDR      0\n",
      "PAQ605        0\n",
      "BMXBMI        0\n",
      "LBXGLU        0\n",
      "LBXGLT        0\n",
      "LBXIN         0\n",
      "DIQ010_1.0    0\n",
      "DIQ010_2.0    0\n",
      "DIQ010_3.0    0\n",
      "dtype: int64\n",
      "\n",
      "--- After Column Alignment ---\n",
      "X_train shape: (1966, 9)\n",
      "X_test shape: (312, 9)\n",
      "X_train columns (first 5): ['BMXBMI', 'DIQ010_1.0', 'DIQ010_2.0', 'DIQ010_3.0', 'LBXGLT']\n",
      "X_test columns (first 5): ['BMXBMI', 'DIQ010_1.0', 'DIQ010_2.0', 'DIQ010_3.0', 'LBXGLT']\n",
      "\n",
      "Training RandomForestClassifier...\n",
      "Model training complete.\n",
      "\n",
      "Predictions made on the test set.\n",
      "\n",
      "--- Submission File Head ---\n",
      "    SEQN  age_group\n",
      "0  77017          0\n",
      "1  75580          0\n",
      "2  73820          0\n",
      "3  80489          0\n",
      "4  82047          0\n",
      "\n",
      "Submission file 'submission.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Load the datasets\n",
    "try:\n",
    "    train_df = pd.read_csv('Train_Data.csv')\n",
    "    test_df = pd.read_csv('Test_Data.csv')\n",
    "    sample_submission_df = pd.read_csv('Sample_Submission.csv')\n",
    "    print(\"Datasets loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}. Please ensure 'Train_Data.csv', 'Test_Data.csv', and 'Sample_Submission.csv' are in the same directory.\")\n",
    "    exit() # Exit if files are not found\n",
    "\n",
    "# Display initial information to confirm loading and structure\n",
    "print(\"\\n--- Initial Data Info ---\")\n",
    "print(\"Train Data Info:\")\n",
    "train_df.info()\n",
    "print(\"\\nTest Data Info:\")\n",
    "test_df.info()\n",
    "\n",
    "# Make copies to avoid SettingWithCopyWarning and preserve original dataframes\n",
    "train_df_processed = train_df.copy()\n",
    "test_df_processed = test_df.copy()\n",
    "\n",
    "# Store SEQN from test_df_processed before any dropping/processing for final submission\n",
    "# Ensure SEQN is integer type as per sample submission\n",
    "test_seqn = test_df_processed['SEQN'].fillna(-1).astype(int) # Fill NaNs with -1 before converting to int if any exist temporarily\n",
    "\n",
    "# Drop original SEQN from processing dataframes as it's an identifier and not a feature\n",
    "train_df_processed = train_df_processed.drop('SEQN', axis=1, errors='ignore')\n",
    "test_df_processed = test_df_processed.drop('SEQN', axis=1, errors='ignore')\n",
    "\n",
    "print(\"\\n--- After dropping SEQN ---\")\n",
    "print(\"Train Data Columns:\", train_df_processed.columns.tolist())\n",
    "print(\"Test Data Columns:\", test_df_processed.columns.tolist())\n",
    "\n",
    "# 1. Handle missing values\n",
    "# Impute numerical columns with median\n",
    "numerical_cols = ['BMXBMI', 'LBXGLU', 'LBXGLT', 'LBXIN']\n",
    "# Create a separate imputer for train and test to avoid issues if all values are NaN in a column\n",
    "imputer_numerical_train = SimpleImputer(strategy='median')\n",
    "imputer_numerical_test = SimpleImputer(strategy='median')\n",
    "\n",
    "for col in numerical_cols:\n",
    "    if col in train_df_processed.columns:\n",
    "        train_df_processed[col] = imputer_numerical_train.fit_transform(train_df_processed[[col]])\n",
    "    if col in test_df_processed.columns:\n",
    "        test_df_processed[col] = imputer_numerical_train.transform(test_df_processed[[col]]) # Use train imputer for test data\n",
    "\n",
    "# Impute categorical columns with most frequent (mode)\n",
    "categorical_cols = ['RIAGENDR', 'PAQ605', 'DIQ010']\n",
    "\n",
    "# Impute 'age_group' in train_df_processed before encoding (target variable)\n",
    "if 'age_group' in train_df_processed.columns:\n",
    "    imputer_age_group = SimpleImputer(strategy='most_frequent')\n",
    "    # Fix: Use .ravel() to flatten the 2D output of fit_transform to a 1D array\n",
    "    train_df_processed['age_group'] = imputer_age_group.fit_transform(train_df_processed[['age_group']]).ravel()\n",
    "    print(f\"\\nMissing values in 'age_group' handled: {train_df_processed['age_group'].isnull().sum()} remaining.\")\n",
    "\n",
    "imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
    "for col in categorical_cols:\n",
    "    if col in train_df_processed.columns:\n",
    "        # Fit on train, transform on train and test\n",
    "        train_df_processed[col] = imputer_categorical.fit_transform(train_df_processed[[col]])\n",
    "    if col in test_df_processed.columns:\n",
    "        test_df_processed[col] = imputer_categorical.transform(test_df_processed[[col]])\n",
    "\n",
    "print(\"\\n--- After Imputation ---\")\n",
    "print(\"Train Data NaNs after numerical and categorical imputation:\\n\", train_df_processed.isnull().sum())\n",
    "print(\"Test Data NaNs after numerical and categorical imputation:\\n\", test_df_processed.isnull().sum())\n",
    "\n",
    "\n",
    "# 2. Encode target variable 'age_group' in training data\n",
    "if 'age_group' in train_df_processed.columns:\n",
    "    train_df_processed['age_group'] = train_df_processed['age_group'].map({'Adult': 0, 'Senior': 1})\n",
    "    if train_df_processed['age_group'].isnull().any():\n",
    "        print(\"Warning: Some 'age_group' values could not be mapped to 0 or 1. Re-imputing if any NaNs exist after mapping.\")\n",
    "        # If any values outside 'Adult'/'Senior' were present, they would become NaN after map.\n",
    "        # Impute again if necessary (e.g., if there were values like 'Child' or 'Teenager')\n",
    "        train_df_processed['age_group'].fillna(train_df_processed['age_group'].mode()[0], inplace=True)\n",
    "    print(\"\\n'age_group' mapped to numerical (0=Adult, 1=Senior).\")\n",
    "else:\n",
    "    print(\"\\n'age_group' column not found in training data. Cannot encode target.\")\n",
    "    exit() # Exit if target column is missing\n",
    "\n",
    "# 3. Encode categorical features\n",
    "# For RIAGENDR and PAQ605, LabelEncoder is suitable since they are binary/ordinal.\n",
    "# Ensure columns exist before encoding\n",
    "if 'RIAGENDR' in train_df_processed.columns:\n",
    "    le_gender = LabelEncoder()\n",
    "    train_df_processed['RIAGENDR'] = le_gender.fit_transform(train_df_processed['RIAGENDR'])\n",
    "    if 'RIAGENDR' in test_df_processed.columns:\n",
    "        test_df_processed['RIAGENDR'] = le_gender.transform(test_df_processed['RIAGENDR'])\n",
    "else:\n",
    "    print(\"Warning: 'RIAGENDR' not found in data for encoding.\")\n",
    "\n",
    "if 'PAQ605' in train_df_processed.columns:\n",
    "    le_paq605 = LabelEncoder()\n",
    "    train_df_processed['PAQ605'] = le_paq605.fit_transform(train_df_processed['PAQ605'])\n",
    "    if 'PAQ605' in test_df_processed.columns:\n",
    "        test_df_processed['PAQ605'] = le_paq605.transform(test_df_processed['PAQ605'])\n",
    "else:\n",
    "    print(\"Warning: 'PAQ605' not found in data for encoding.\")\n",
    "\n",
    "# For DIQ010, use OneHotEncoder\n",
    "if 'DIQ010' in train_df_processed.columns:\n",
    "    # Convert to string/object type first to treat values like 3 and 9 as distinct categories\n",
    "    train_df_processed['DIQ010'] = train_df_processed['DIQ010'].astype(str)\n",
    "    if 'DIQ010' in test_df_processed.columns:\n",
    "        test_df_processed['DIQ010'] = test_df_processed['DIQ010'].astype(str)\n",
    "\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "    # Fit OneHotEncoder on the training data's 'DIQ010' column\n",
    "    ohe.fit(train_df_processed[['DIQ010']])\n",
    "\n",
    "    # Transform 'DIQ010' in both train and test data\n",
    "    diq010_encoded_train = ohe.transform(train_df_processed[['DIQ010']])\n",
    "    diq010_encoded_test = ohe.transform(test_df_processed[['DIQ010']])\n",
    "\n",
    "    # Create DataFrames from the encoded arrays with appropriate column names\n",
    "    diq010_feature_names = ohe.get_feature_names_out(['DIQ010'])\n",
    "\n",
    "    diq010_df_train = pd.DataFrame(diq010_encoded_train, columns=diq010_feature_names, index=train_df_processed.index)\n",
    "    diq010_df_test = pd.DataFrame(diq010_encoded_test, columns=diq010_feature_names, index=test_df_processed.index)\n",
    "\n",
    "    # Concatenate the new one-hot encoded columns to the dataframes and drop the original 'DIQ010'\n",
    "    train_df_processed = pd.concat([train_df_processed.drop('DIQ010', axis=1), diq010_df_train], axis=1)\n",
    "    test_df_processed = pd.concat([test_df_processed.drop('DIQ010', axis=1), diq010_df_test], axis=1)\n",
    "    print(\"\\n'DIQ010' one-hot encoded.\")\n",
    "else:\n",
    "    print(\"Warning: 'DIQ010' not found in data for encoding.\")\n",
    "\n",
    "\n",
    "# Ensure all columns are numeric after all encoding steps\n",
    "# This handles cases where mixed types might have caused issues or new NaNs were introduced\n",
    "for col in train_df_processed.columns:\n",
    "    if train_df_processed[col].dtype == 'object':\n",
    "        train_df_processed[col] = pd.to_numeric(train_df_processed[col], errors='coerce')\n",
    "\n",
    "for col in test_df_processed.columns:\n",
    "    if test_df_processed[col].dtype == 'object':\n",
    "        test_df_processed[col] = pd.to_numeric(test_df_processed[col], errors='coerce')\n",
    "\n",
    "# Final imputation for any NaNs introduced by to_numeric (should be minimal if preprocessing was correct)\n",
    "train_df_processed.fillna(train_df_processed.median(), inplace=True)\n",
    "test_df_processed.fillna(test_df_processed.median(), inplace=True)\n",
    "\n",
    "print(\"\\n--- After all preprocessing and final imputation ---\")\n",
    "print(\"Train Data Columns:\", train_df_processed.columns.tolist())\n",
    "print(\"Test Data Columns:\", test_df_processed.columns.tolist())\n",
    "print(\"Train Data NaNs:\\n\", train_df_processed.isnull().sum())\n",
    "print(\"Test Data NaNs:\\n\", test_df_processed.isnull().sum())\n",
    "\n",
    "\n",
    "# 4. Separate features and target\n",
    "# Ensure 'age_group' exists in train_df_processed\n",
    "if 'age_group' in train_df_processed.columns:\n",
    "    X_train = train_df_processed.drop('age_group', axis=1)\n",
    "    y_train = train_df_processed['age_group']\n",
    "else:\n",
    "    print(\"Error: 'age_group' column not found in processed training data.\")\n",
    "    exit()\n",
    "\n",
    "X_test = test_df_processed\n",
    "\n",
    "# Align columns - crucial for consistency between training and test sets after one-hot encoding\n",
    "# Get all unique columns from both train and test features\n",
    "# Exclude 'age_group' from this alignment as it's the target\n",
    "train_features_cols = X_train.columns.tolist()\n",
    "test_features_cols = X_test.columns.tolist()\n",
    "\n",
    "all_common_features = sorted(list(set(train_features_cols) | set(test_features_cols)))\n",
    "\n",
    "# Reindex both dataframes to have all_common_features, filling missing with 0\n",
    "X_train = X_train.reindex(columns=all_common_features, fill_value=0)\n",
    "X_test = X_test.reindex(columns=all_common_features, fill_value=0)\n",
    "\n",
    "# Ensure the order of columns is exactly the same for training and testing\n",
    "# This ensures that features map correctly to the model's learned weights\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "print(\"\\n--- After Column Alignment ---\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"X_train columns (first 5):\", X_train.columns.tolist()[:5])\n",
    "print(\"X_test columns (first 5):\", X_test.columns.tolist()[:5])\n",
    "\n",
    "\n",
    "# 5. Train a classification model (RandomForestClassifier)\n",
    "print(\"\\nTraining RandomForestClassifier...\")\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced') # Added class_weight for potential imbalance\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# 6. Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "print(\"\\nPredictions made on the test set.\")\n",
    "\n",
    "# 7. Create the submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'SEQN': test_seqn, # Use the stored SEQN values\n",
    "    'age_group': predictions\n",
    "})\n",
    "\n",
    "# Display the first few rows of the submission file\n",
    "print(\"\\n--- Submission File Head ---\")\n",
    "print(submission_df.head())\n",
    "\n",
    "# Save the submission file\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"\\nSubmission file 'submission.csv' created successfully.\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
